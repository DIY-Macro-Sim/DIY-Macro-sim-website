{
  "hash": "a6f322de302d520ee017c234dbfc1f20",
  "result": {
    "engine": "knitr",
    "markdown": "# An Evolutionary Game Theoretic Model of the Emergence of Property Rights  {#sec-evolutionary}\n\n## Overview\n\n[Evolutionary game theory (EGT)](https://en.wikipedia.org/wiki/Evolutionary_game_theory) has its origins in evolutionary biology, where it was developed to study how behavioural strategies evolve within populations. It combines concepts from game theory, such as strategic interactions and their resulting payoffs, with Darwinian evolutionary biology, in particular the idea of differential replication (selection). Populations are assumed to consist of repeatedly interacting agents that follow different strategies with different payoffs. More successful strategies will reproduce faster, thereby increasing their frequencies in the population. EGT studies different strategies, their performance, and the possible equilibria that may emerge over time, which can involve the extinction, dominance, or co-existence of various strategies.^[EGT has been popularised by Richard Dawkin's 1976 book [The Selfish Gene](https://en.wikipedia.org/wiki/The_Selfish_Gene) and Robert Axelrod's 1984 book [The Evolution of Cooperation](https://en.wikipedia.org/wiki/The_Evolution_of_Cooperation). The latter contributed to the application of EGT to the social sciences and is also regarded as a milestone in the development of agent-based modelling. While EGT has predominantly been applied to microeconomic issues, there have been influences on macroeconomics as well. A first path through which EGT has impacted macroeconomics has been via heterogeneous agent models in finance that study speculative dynamics in asset markets driven by competing trading strategies (see  @Dieci2018 for a review). @Franke2017 review approaches that introduce these behavioural dynamics into macroeconomics. A second path has been via models of dynamic competition in evolutionary economics (e.g. @Metcalfe1994), elements of which have fed into macroeconomic agent-based models (@Dosi2010).] Unlike classical game theory which typically assumes agents to be fully rational, EGT assumes agents to follow simple rules whose relative success is not known to the agents in advance. \n\nIn this section, we present a continuous-time model from @Bowles2004, chapter 11, which seeks to illuminate the logic behind the emergence of property rights.^[@sec-sim-continuous explains how continuous time models can be solved numerically.] It asks how social norms that ensure the enforcement of property rights could evolve through the repeated interaction of agents. The model features three types of strategies: sharing, grabbing, and punishing. For property rights to be respected, the grabbing strategy needs to be contained through sufficiently pervasive punishing. A particularly interesting feature of the model, both from an economic and a technical perspective, is that its outcomes depend on initial conditions. The model thus captures a form of path dependence, where a historically given distribution of behavioural rules impacts not only the subsequent trajectory, but also the long-run equilibrium that will emerge.^[The model from @Bowles2004, chapter 11, has subsequently been developed further and supplemented with empirical evidence in @Bowles2013 and @Bowles2019.]  \n\n## The strategies and their payoffs\nThere are $n$ members of a population that are paired randomly to divide a good whose value is $v$. They can adopt one of three strategies: sharing, grabbing, or punishing. When Sharers meet, they divide the good equally. When Grabbers meet Sharers, they grab the good from the Sharers. When Grabbers meet other Grabbers, they fight and win or bear the costs of defeat $c > v$ with equal probability. Punishers meeting Sharers or other Punishers divide the good equally. When Punishers meets Grabbers, they attempt to punish the Grabbers collectively. If successful, an individual Punisher will distribute the good equally among all Punishers, otherwise it bears the cost of defeat $c$. Because punishing is a collective strategy, its probability of success depends on the population frequency of Punishers. For simplicity, it is assumed that the probability of success is equal to the population frequency of Punishers, $\\beta$. With these assumptions, the payoffs of the different interactions are given in Table 1.\n\n**Table 1: Payoffs (for individual row players)**\n\n|           | Share       | Grab                  | Punish             |\n|-----------|-------------|-----------------------|--------------------|\n| **Share** | v/2         | 0                    | v/2                 |\n| **Grab**  | v           |  (v - c)/2           | (1 - $\\beta$)v - $\\beta$c |\n| **Punish**|  v/2      |  v/n - (1 - $\\beta$)c  | v/2             |\n\n\n## The model\nThe model equations are:\n$$\n\\pi^S_{t}=0.5v(\\alpha_t + \\beta_t)\n$$ {#eq-evolutionary_pi-s}\n\n\n$$\n\\pi^P_{t} = 0.5v(\\alpha_t + \\beta_t) + (1-\\alpha_t -\\beta_t)[\\beta_t v - (1-\\beta_t)c)]\n$$ {#eq-evolutionary_pi-p}\n\n$$\n\\pi^G_{t} = \\alpha_t v + \\beta_t[(1-\\beta_t)v-\\beta_t c] + 0.5(1-\\alpha_t -\\beta_t)(v-c)\n$$ {#eq-evolutionary_pi-g}\n\n\n$$\n\\dot{\\alpha}=\\alpha_t( \\pi^S_{t} - \\bar{\\pi})\n$$ {#eq-evolutionary_alpha-dot}\n\n$$\n\\dot{\\beta}=\\beta_t( \\pi^G_{t} - \\bar{\\pi})\n$$ {#eq-evolutionary_beta-dot}\n\n$$\n\\bar{\\pi}_t=\\alpha_t \\pi^S_{t} + \\beta_t \\pi^P_{t} +\\gamma_t \\pi^G_{t}\n$$ {#eq-evolutionary_pi-avr}\n\n$$\n\\gamma_t=1-\\alpha_t -\\beta_t\n$$ {#eq-evolutionary_gamma}\n\nwhere $\\pi^S_{t}$, $\\pi^P_{t}$, and $\\pi^G_{t}$ represent the expected payoffs of Sharers, Punishers, and Grabbers, and $\\alpha$, $\\beta$, and $\\gamma$ are their respective population frequencies. $\\bar{\\pi}$ is the (weighted) average payoff. $v$ and $c$ are the value of the good to be divided and the cost of losing a fight, respectively. A dot over a variable represents the derivative with respect to time ($\\dot{x}=\\frac{d x}{d t}$).\n\n@eq-evolutionary_pi-s - @eq-evolutionary_pi-g specify the expected payoffs associated with the three strategies. These follow from the payoffs from the different possible pairings reported in Table 1 together with the population frequencies, which constitute the probabilities of being randomly paired with a player of the respective strategy. To find the expected payoff for Punishers, consider what happens in interactions with Grabbers. The value in Table 1, *v/n - (1 - $\\beta$)c*, represents the payoff for an individual Punisher in an interaction with a Grabber. However, in every period, there are $\\beta n - 1$ other Punishers, of which $(\\beta n - 1)(1-\\alpha-\\beta)$ will also be paired with Grabbers. Each Punisher will receive $v/\\beta n$ from each of these, yielding an expected amount  $(\\beta n - 1)(1-\\alpha-\\beta)(v/n)$ from redistribution. Adding this expected redistributed payoff to the expected direct payoffs in Table 1 yields the total payoff for Punishers in @eq-evolutionary_pi-p.\n\n@eq-evolutionary_alpha-dot - @eq-evolutionary_beta-dot specify the change in population frequencies of Sharers and Punishers. These so-called *replicator equations* are a key feature of EGT. They encapsulate the idea of selection based on relative fitness: strategies that yield above-average payoffs (as defined in @eq-evolutionary_pi-avr) increase their presence in the population. While in biological applications, strategies are typically conceived as genetically inherited and replication as sexual reproduction, in social applications, replication may occur through a cultural transmission process and/or adaptive learning.\n\nWith the population dynamics of Sharers and Punishers determined, the frequency of Grabbers follows residually (@eq-evolutionary_gamma).\n \n\n## Simulation\n\n### Parameterisation\n\nTable 2 reports the initialisations used in the simulations. We will keep the parameters $v$ and $c$ fixed and study how different initialisations of the population shares give rise to different equilibria, whose interpretation ('Hobbesian' vs 'Rousseauian') will be discussed below.\n\n**Table 2: Initialisations**\n\n| Initialisations                     | $v$  |$c$  | $\\alpha_0$ | $\\beta_0$ | $\\gamma_0$ |\n|------------------------------------ |:---- |:--- |:---------- |:-------- |:-----------|\n| 1: Hobbesian equilibrium            |  2   | 3   |  1/3       |  1/3     |  1/3       | \n| 2: Rousseauian equilibrium #1       |  2   | 3   |  0.2       |  0.6     |  0.2       | \n| 2: Rousseauian equilibrium #2       |  2   | 3   |  0.1       |  0.6     |  0.3       | \n\n\n### Simulation code\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Clear the environment\nrm(list=ls(all=TRUE))\n\n#Set number of periods\nQ = 1000\n\n# time increment\nd=0.1   \n\n# Set number of initialisations\nS=3\n\n# Set constant parameter values\nv=2   # value of good to be divided\nc=3   # cost of defeat\n\n#Create (S x Q) matrices in which equilibrium solutions from different initialisations will be stored\npi_S=matrix(data=0.5, nrow=S, ncol=Q)   # payoffs for Sharers\npi_P=matrix(data=0.5, nrow=S, ncol=Q)   # payoffs for Punishers \npi_G=matrix(data=0.5, nrow=S, ncol=Q)   # payoffs for Grabber \npi_bar=matrix(data=0.5, nrow=S, ncol=Q) # average payoffs\nalpha=matrix(data=0, nrow=S, ncol=Q)    # population frequency of Sharers\nbeta=matrix(data=0, nrow=S, ncol=Q)     # population frequency of Punishers\ngamma=matrix(data=0, nrow=S, ncol=Q)    # population frequency of Grabbers\n\n### Initialise population shares\n# Hobbesian equilibrium \nalpha[1, 1]=1/3\nbeta[1, 1]=1/3\ngamma[1, 1]=1- alpha[1, 1] - beta[1, 1]\n\n# Rousseauian equilibrium #1\nalpha[2, 1]=0.2\nbeta[2, 1]=0.6 \ngamma[2, 1]=1- alpha[2, 1] - beta[2, 1]\n\n# Rousseauian equilibrium #2\nalpha[3, 1]=0.1\nbeta[3, 1]=0.6\ngamma[3, 1]=1- alpha[3, 1] - beta[3, 1]\n\n# Simulate the model by looping over Q time periods for S different initialisations\nfor (i in 1:S){\n  \n  for (t in 2:Q){\n    \n    # Population share of Sharers\n    alpha[i,t] = alpha[i,t-1] + alpha[i,t-1]*(pi_S[i,t-1] - pi_bar[i,t-1])*d\n    \n    # Population share of Punishers\n    beta[i,t] = beta[i,t-1] + beta[i,t-1]*(pi_P[i,t-1] - pi_bar[i,t-1])*d\n    \n    # Population share of Grabbers\n    gamma[i,t]=1- alpha[i, t] - beta[i, t]\n    \n    # Payoffs of Sharers  \n    pi_S[i,t] = 0.5*v*(alpha[i,t] + beta[i,t])\n    \n    # Payoffs of Punishers  \n    pi_P[i,t] = 0.5*v*(alpha[i,t] + beta[i,t]) + (1-alpha[i,t]-beta[i,t])*(beta[i,t]*v-(1-beta[i,t])*c)\n    \n    # Payoffs of Grabbers\n    pi_G[i,t] = alpha[i,t]*v + beta[i,t]*((1-beta[i,t])*v-beta[i,t]*c) + (1-alpha[i,t]-beta[i,t])*0.5*(v-c)\n    \n    # Average payoffs\n    pi_bar[i,t] = alpha[i,t]*pi_S[i,t] + beta[i,t]*pi_P[i,t] + (1-alpha[i,t]-beta[i,t])*pi_G[i,t]\n    \n  }  # close time loop\n}   # close scenarios loop\n```\n:::\n\n\n::: {.callout-note collapse=\"true\" title=\"Python code\"}\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\n\n# Set number of periods\nQ = 1000\n\n# Time increment\nd = 0.1   \n\n# Set number of initialisations\nS = 3\n\n# Set constant parameter values\nv = 2   # value of good to be divided\nc = 3   # cost of defeat\n\n# Create (S x Q) matrices in which equilibrium solutions from different initialisations will be stored\npi_S = np.full((S, Q), 0.5)   # payoffs for Sharers\npi_P = np.full((S, Q), 0.5)   # payoffs for Punishers \npi_G = np.full((S, Q), 0.5)   # payoffs for Grabbers \npi_bar = np.full((S, Q), 0.5) # average payoffs\nalpha = np.zeros((S, Q))      # population frequency of Sharers\nbeta = np.zeros((S, Q))       # population frequency of Punishers\ngamma = np.zeros((S, Q))      # population frequency of Grabbers\n\n### Initialise population shares\n# Hobbesian equilibrium \nalpha[0, 0] = 1/3\nbeta[0, 0] = 1/3\ngamma[0, 0] = 1 - alpha[0, 0] - beta[0, 0]\n\n# Rousseauian equilibrium #1\nalpha[1, 0] = 0.2\nbeta[1, 0] = 0.6 \ngamma[1, 0] = 1 - alpha[1, 0] - beta[1, 0]\n\n# Rousseauian equilibrium #2\nalpha[2, 0] = 0.1\nbeta[2, 0] = 0.6\ngamma[2, 0] = 1 - alpha[2, 0] - beta[2, 0]  \n\n# Simulate the model by looping over Q time periods for S different initializations\nfor i in range(S):\n    \n    for t in range(1, Q):\n        \n        # Population share of Sharers\n        alpha[i, t] = alpha[i, t-1] + alpha[i, t-1] * (pi_S[i, t-1] - pi_bar[i, t-1]) * d\n        \n        # Population share of Punishers\n        beta[i, t] = beta[i, t-1] + beta[i, t-1] * (pi_P[i, t-1] - pi_bar[i, t-1]) * d\n        \n        # Population share of Grabbers\n        gamma[i, t] = 1 - alpha[i, t] - beta[i, t]\n        \n        # Payoffs of Sharers  \n        pi_S[i, t] = 0.5 * v * (alpha[i, t] + beta[i, t])\n        \n        # Payoffs of Punishers  \n        pi_P[i, t] = (0.5 * v * (alpha[i, t] + beta[i, t]) + \n                      (1 - alpha[i, t] - beta[i, t]) * (beta[i, t] * v - (1 - beta[i, t]) * c))\n        \n        # Payoffs of Grabbers\n        pi_G[i, t] = (alpha[i, t] * v + \n                      beta[i, t] * ((1 - beta[i, t]) * v - beta[i, t] * c) + \n                      (1 - alpha[i, t] - beta[i, t]) * 0.5 * (v - c))\n        \n        # Average payoffs\n        pi_bar[i, t] = (alpha[i, t] * pi_S[i, t] + \n                        beta[i, t] * pi_P[i, t] + \n                        (1 - alpha[i, t] - beta[i, t]) * pi_G[i, t])\n        \n```\n:::\n\n\n:::\n\n\n### Plots\n@fig-hobbes displays the population shares for the first initialisation, giving rise to what @Bowles2004 calls the 'Hobbesian equilibrium'. In this equilibrium, the Punishers have died out and the population is split into Sharers and Grabbers. Due to the strong presence of Grabbers, this equilibrium is characterised by frequent fighting that goes unpunished. The red horizontal line displays the average equilibrium payoff. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set start and end periods for plots\nTmin =3\nTmax=100\n\n# Hobbesian equilibrium\nplot(alpha[1, 1:Q],type=\"l\", col=1, lwd=2, lty=1, xlab=\"Time\", ylab=\"Population shares\", ylim=range(0,1), xlim=c(Tmin,Tmax))\ntitle(main=\"\", cex=0.8)\nlines(beta[1, 1:Q],lty=2)\nlines(gamma[1, 1:Q],lty=3)\nabline(h=pi_bar[1,Q], col=2)\nlegend(\"topright\", legend=c(\"Sharers\", \"Punishers\", \"Grabbers\"),\n       lty=1:3, cex=0.8, bty = \"n\", y.intersp=0.8)\n```\n\n::: {.cell-output-display}\n![Hobbesian equilibrium](an_evolutionary_game_theoretic_model_files/figure-html/fig-hobbes-1.png){#fig-hobbes width=672}\n:::\n:::\n\n@fig-rousseau1 and @fig-rousseau2 display the population shares for the other two initialisations that yield 'Rousseauian' equilibria. In these equilibria, the Grabbers have died out and the population is split into Sharers and Punishers. As a result, property rights are respected and social norms of peaceful sharing are upheld. The average equilibrium payoff are higher compared to the Hobbesian equilibrium due to the absence of costly losses from fighting Thus, social welfare in the cooperative Rousseauian equilibrium is higher compared to the conflictive Hobbesian equilibrium.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Rousseauian equilibrium 1\nplot(alpha[2, 1:Q],type=\"l\", col=1, lwd=2, lty=1, xlab=\"Time\", ylab=\"Population shares\", \n     ylim=range(0,1),xlim=c(Tmin,Tmax))\ntitle(main=\"\", cex=0.8)\nlines(beta[2, 1:Q],lty=2)\nlines(gamma[2, 1:Q],lty=3)\nabline(h=pi_bar[2,Q], col=2)\nlegend(\"right\", legend=c(\"Sharers\", \"Punishers\", \"Grabbers\"),\n       lty=1:3, cex=0.8, bty = \"n\", y.intersp=0.8)\n```\n\n::: {.cell-output-display}\n![Rousseauian equilibrium, no. 1](an_evolutionary_game_theoretic_model_files/figure-html/fig-rousseau1-1.png){#fig-rousseau1 width=672}\n:::\n:::\n\n\n@fig-rousseau2 represents another incidence of the Rousseauian equilibrium resulting from a different initialisation. Grabber again have died out, but the composition of Sharers and Grabbers is different from the one in @fig-rousseau1, with a higher share of Punishers. This result suggests that the Rousseauian equilibrium is stable but not unique.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Rousseauian equilibrium 2\nplot(alpha[3, 1:Q],type=\"l\", col=1, lwd=2, lty=1, xlab=\"Time\", ylab=\"Population shares\", \n     ylim=range(0,1),xlim=c(Tmin,Tmax))\ntitle(main=\"\", cex=0.8)\nlines(beta[3, 1:Q],lty=2)\nlines(gamma[3, 1:Q],lty=3)\nabline(h=pi_bar[3,Q], col=2)\nlegend(\"right\", legend=c(\"Sharers\", \"Punishers\", \"Grabbers\"),\n       lty=1:3, cex=0.8, bty = \"n\", y.intersp=0.8)\n```\n\n::: {.cell-output-display}\n![Rousseauian equilibrium, no. 2](an_evolutionary_game_theoretic_model_files/figure-html/fig-rousseau2-1.png){#fig-rousseau2 width=672}\n:::\n:::\n\n\n::: {.callout-note collapse=\"true\" title=\"Python code\"}\n\n\n::: {.cell}\n\n```{.python .cell-code}\n## Plot results (here only for the Hobbesian equilibrium)\n\nimport matplotlib.pyplot as plt\n\n# Set start and end periods for plots\nTmin = 3\nTmax = 100\n\n# Hobbesian equilibrium\nplt.figure(figsize=(8, 5))\nplt.plot(range(Q), alpha[0, :], label=\"Sharers\", color='black', linewidth=2, linestyle='-')\nplt.title(\"\")  \nplt.xlabel(\"Time\")\nplt.ylabel(\"Population shares\")\nplt.ylim(0, 1)\nplt.xlim(Tmin, Tmax)\nplt.plot(range(Q), beta[0, :], linestyle='--', color='black', label=\"Punishers\")\nplt.plot(range(Q), gamma[0, :], linestyle=':', color='black', label=\"Grabbers\")\nplt.axhline(y=pi_bar[0, Q-1], color='red')  \nplt.legend(loc='upper right', fontsize=8, frameon=False)  \nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n:::\n\n### Creating an interactive 3D diagram of the basins of attraction\nThe finding that different Rousseauian equilibria emerge from different initialisations warrants a more detailed examination of the dependence of the equilibria on initial values. In this section, we show how to create a diagram of the 'basins of attraction' of the different equilibria, which map a set of initial conditions to the corresponding equilibria. To this end, we need to simulate the model for different values of the initial conditions and store the results.\n\nThe following code first creates a function called *bowles* that will be used to simulate @Bowles2004's EGT model for different initial values and store the results in a data frame. We then create a grid of initial values $\\alpha_0 \\in [0,1]$ and $\\beta_0 \\in [0,1]$ considering increments of $0.05$.^[Finer grids are possible but will increase computation time.] Inadmissible combinations of $\\alpha_0$ and $\\beta_0$ whose sum exceeds unity are removed from the grid. The function is then executed for all combinations on the grid, and the resulting data are appended as rows to a matrix.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define a function called \"bowles\" that simulates the model for different initialisations\nbowles =function(alpha_0, beta_0) {\n  \n  # Initialise data matrices \n  pi_S = rep(0.5, Q)\n  pi_P = rep(0.5, Q)\n  pi_G = rep(0.5, Q)\n  pi_bar = rep(0.5, Q)\n  \n  alpha = rep(NA, Q)\n  beta = rep(NA, Q)\n  gamma = rep(NA, Q)\n  \n  # Initialise population shares\n  alpha[1] = alpha_0\n  beta[1] = beta_0\n  gamma[1] = round(1 - alpha[1] - beta[1], digits=2)\n  \n  # Simulate model\n  for (t in 2:Q) {\n    alpha[t] = alpha[t-1] + alpha[t-1] * (pi_S[t-1] - pi_bar[t-1]) * d\n    beta[t]  = beta[t-1] + beta[t-1] * (pi_P[t-1] - pi_bar[t-1]) * d\n    gamma[t] = 1 - alpha[t] - beta[t]\n    \n    pi_S[t] = 0.5 * v * (alpha[t] + beta[t])\n    pi_P[t] = 0.5 * v * (alpha[t] + beta[t]) + (1 - alpha[t] - beta[t]) * (beta[t]*v - (1 - beta[t]) * c)\n    pi_G[t] = alpha[t] * v + beta[t] * ((1 - beta[t]) * v - beta[t] * c) + (1 - alpha[t] - beta[t]) * 0.5 * (v - c)\n    pi_bar[t] = alpha[t] * pi_S[t] + beta[t] * pi_P[t] + (1 - alpha[t] - beta[t]) * pi_G[t]\n  } # close time loop\n  \n  # Return final values in a dataframe\n  data.frame(\n    alpha_0 = alpha_0,\n    beta_0 = beta_0,\n    gamma_0= gamma[1],\n    alpha_T = round(alpha[Q], digits=3),\n    beta_T = round(beta[Q], digits=3),\n    gamma_T = round(gamma[Q], digits=3),\n    pi_S_T = round(pi_S[Q], digits=3),\n    pi_P_T = round(pi_P[Q], digits=3),\n    pi_G_T = round(pi_G[Q], digits=3),\n    pi_bar =round(pi_bar[Q], digits=3)\n    )\n} # close function\n\n# Create grid of initial values for alpha and beta\ngrid=expand.grid(\n  alpha_0 = seq(0, 1, by = 0.05),\n  beta_0 = seq(0, 1, by = 0.05)\n)\n\n# Exclude invalid combinations where alpha + beta > 1\ngrid=subset(grid, alpha_0 + beta_0 <= 1)\n\n# Execute the function over the grid and append data from each run as rows to a matrix named \"results\"\nresults=do.call(rbind, lapply(1:nrow(grid), function(i) {\n  bowles(grid$alpha_0[i], grid$beta_0[i])\n}))\n```\n:::\n\n\nHaving simulated the data for different initialisations, @fig-equilibria plots the equilibrium values for the population shares from the different runs. It can be seen that three types of equilibria are possible. First, the unique Hobbesian equilibrium where $\\beta^*=0$. Second, a continuum of Rousseauian equilibria, where $\\gamma^*=0$ and $\\alpha^*+\\beta^*=1$. Third, a unique equilibrium where $\\gamma^*=1$ and $\\alpha^*=\\beta^*=0$. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Install plotly package to create 3D plots\n#install.packages(\"plotly\")\n\n# Load plotly package to create 3D plots\nlibrary(plotly)\n\n# Create a 3D scatter plot of the final values of the population shares using the data from different initialisations\nfig_endog =plot_ly(\n  data = results, \n  x = ~alpha_T, \n  y = ~beta_T, \n  z = ~gamma_T,\n  type = \"scatter3d\",\n  mode = \"markers\",\n  marker = list(size = 3, showscale = FALSE)\n)\n\nfig_endog = fig_endog %>% layout(\n  scene = list(\n    xaxis = list(title = \"alpha_T\"),\n    yaxis = list(title = \"beta_T\"),\n    zaxis = list(title = \"gamma_T\")\n  ),\n  title = \"\"\n)\n\n# Show plot\nfig_endog\n```\n\n::: {#fig-equilibria .cell-output-display}\n\n```{=html}\n<div class=\"plotly html-widget html-fill-item\" id=\"htmlwidget-a788ca842b56f8574682\" style=\"width:100%;height:464px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-a788ca842b56f8574682\">{\"x\":{\"visdat\":{\"614c70a4904\":[\"function () \",\"plotlyVisDat\"]},\"cur_data\":\"614c70a4904\",\"attrs\":{\"614c70a4904\":{\"x\":{},\"y\":{},\"z\":{},\"mode\":\"markers\",\"marker\":{\"size\":3,\"showscale\":false},\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"scatter3d\"}},\"layout\":{\"margin\":{\"b\":40,\"l\":60,\"t\":25,\"r\":10},\"scene\":{\"xaxis\":{\"title\":\"alpha_T\"},\"yaxis\":{\"title\":\"beta_T\"},\"zaxis\":{\"title\":\"gamma_T\"}},\"title\":\"\",\"hovermode\":\"closest\",\"showlegend\":false},\"source\":\"A\",\"config\":{\"modeBarButtonsToAdd\":[\"hoverclosest\",\"hovercompare\"],\"showSendToCloud\":false},\"data\":[{\"x\":[0,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,1,0,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.94999999999999996,0,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.90000000000000002,0,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.84999999999999998,0,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.80000000000000004,0,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.75,0,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.69999999999999996,0,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.65000000000000002,0,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.59999999999999998,0,0.111,0.21299999999999999,0.311,0.42699999999999999,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.33300000000000002,0.55000000000000004,0,0.086999999999999994,0.16500000000000001,0.23499999999999999,0.29799999999999999,0.35299999999999998,0.40200000000000002,0.44400000000000001,0.47599999999999998,0.495,0.5,0,0.075999999999999998,0.14399999999999999,0.20599999999999999,0.26200000000000001,0.311,0.35499999999999998,0.39300000000000002,0.42499999999999999,0.45000000000000001,0,0.069000000000000006,0.13200000000000001,0.189,0.24099999999999999,0.28799999999999998,0.33000000000000002,0.36699999999999999,0.40000000000000002,0,0.064000000000000001,0.123,0.17699999999999999,0.22600000000000001,0.27200000000000002,0.313,0.34999999999999998,0,0.059999999999999998,0.11600000000000001,0.16800000000000001,0.216,0.26000000000000001,0.29999999999999999,0,0.057000000000000002,0.111,0.161,0.20699999999999999,0.25,0,0.055,0.107,0.155,0.20000000000000001,0,0.052999999999999999,0.10299999999999999,0.14999999999999999,0,0.050999999999999997,0.10000000000000001,0,0.050000000000000003,0],\"y\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.050000000000000003,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.10000000000000001,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.14999999999999999,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.20000000000000001,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.29999999999999999,0,0,0,0,0,0,0,0,0,0,0,0,0,0.34999999999999998,1,0,0,0,0,0,0,0,0,0,0,0,0.40000000000000002,1,0.88900000000000001,0.78700000000000003,0.68899999999999995,0.57299999999999995,0,0,0,0,0,0,0.45000000000000001,1,0.91300000000000003,0.83499999999999996,0.76500000000000001,0.70199999999999996,0.64700000000000002,0.59799999999999998,0.55600000000000005,0.52400000000000002,0.505,0.5,1,0.92400000000000004,0.85599999999999998,0.79400000000000004,0.73799999999999999,0.68899999999999995,0.64500000000000002,0.60699999999999998,0.57499999999999996,0.55000000000000004,1,0.93100000000000005,0.86799999999999999,0.81100000000000005,0.75900000000000001,0.71199999999999997,0.67000000000000004,0.63300000000000001,0.59999999999999998,1,0.93600000000000005,0.877,0.82299999999999995,0.77400000000000002,0.72799999999999998,0.68700000000000006,0.65000000000000002,1,0.93999999999999995,0.88400000000000001,0.83199999999999996,0.78400000000000003,0.73999999999999999,0.69999999999999996,1,0.94299999999999995,0.88900000000000001,0.83899999999999997,0.79300000000000004,0.75,1,0.94499999999999995,0.89300000000000002,0.84499999999999997,0.80000000000000004,1,0.94699999999999995,0.89700000000000002,0.84999999999999998,1,0.94899999999999995,0.90000000000000002,1,0.94999999999999996,1],\"z\":[1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0,1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0,1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,0,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,0,0,0,0,0,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-0,0,0,0,0,0,0,0,-0,0,0,0,0,0,0,-0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-0,0,0,0,0,-0,0],\"mode\":\"markers\",\"marker\":{\"color\":\"rgba(31,119,180,1)\",\"size\":3,\"showscale\":false,\"line\":{\"color\":\"rgba(31,119,180,1)\"}},\"type\":\"scatter3d\",\"error_y\":{\"color\":\"rgba(31,119,180,1)\"},\"error_x\":{\"color\":\"rgba(31,119,180,1)\"},\"line\":{\"color\":\"rgba(31,119,180,1)\"},\"frame\":null}],\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.20000000000000001,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n\nPopulation shares -- possible equilibria\n:::\n:::\n\n\n@fig-basin plots the basin of attraction of $\\gamma^*$ for different initialisations $(\\alpha_0, \\beta_0)$. This shows the dependence of the three types of equilibria on the initialisation. The Hobbesian equilibrium yielding $\\gamma^* \\in [0,1]$ can occur for a relatively wide range of $\\alpha_0 \\in [0,1]$ values, but a narrower range of $\\beta_0 \\in (0,\\beta^H]$ with an upper bound $\\beta^H \\approx 0.45$. Intuitively, if there are too many Punishers, they cannot be pushed away by the Grabbers. In contrast, the Rousseauian equilibria where $\\gamma^* =0$ require either a relatively high initial share of Punishers or Sharers (or both). Finally, the third equilibrium where $\\gamma^* =1$ can only occur for initialisations without Sharers ($\\alpha_0=0$) and a low share of Punishers (roughly below 0.35).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a 3D scatter plot of the final values of the population share of Grabbers (gamma) for different initialisations\nfig_gamma =plot_ly(\n  data = results, \n  x = ~alpha_0, \n  y = ~beta_0, \n  z = ~gamma_T,\n  type = \"scatter3d\",\n  mode = \"markers\",\n  marker = list(size = 3, color = ~gamma_T, colorscale = \"Viridis\", showscale = TRUE)\n)\n\nfig_gamma = fig_gamma %>% layout(\n  scene = list(\n    xaxis = list(title = \"alpha_0\"),\n    yaxis = list(title = \"beta_0\"),\n    zaxis = list(title = \"gamma_T\")\n  ),\n  title = \"\"\n)\n\n# Show plot\nfig_gamma\n```\n\n::: {#fig-basin .cell-output-display}\n\n```{=html}\n<div class=\"plotly html-widget html-fill-item\" id=\"htmlwidget-d12bee8f1dbbab562bb3\" style=\"width:100%;height:464px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-d12bee8f1dbbab562bb3\">{\"x\":{\"visdat\":{\"614c1c6a3a0d\":[\"function () \",\"plotlyVisDat\"]},\"cur_data\":\"614c1c6a3a0d\",\"attrs\":{\"614c1c6a3a0d\":{\"x\":{},\"y\":{},\"z\":{},\"mode\":\"markers\",\"marker\":{\"size\":3,\"color\":{},\"colorscale\":\"Viridis\",\"showscale\":true},\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"scatter3d\"}},\"layout\":{\"margin\":{\"b\":40,\"l\":60,\"t\":25,\"r\":10},\"scene\":{\"xaxis\":{\"title\":\"alpha_0\"},\"yaxis\":{\"title\":\"beta_0\"},\"zaxis\":{\"title\":\"gamma_T\"}},\"title\":\"\",\"hovermode\":\"closest\",\"showlegend\":false},\"source\":\"A\",\"config\":{\"modeBarButtonsToAdd\":[\"hoverclosest\",\"hovercompare\"],\"showSendToCloud\":false},\"data\":[{\"x\":[0,0.050000000000000003,0.10000000000000001,0.15000000000000002,0.20000000000000001,0.25,0.30000000000000004,0.35000000000000003,0.40000000000000002,0.45000000000000001,0.5,0.55000000000000004,0.60000000000000009,0.65000000000000002,0.70000000000000007,0.75,0.80000000000000004,0.85000000000000009,0.90000000000000002,0.95000000000000007,1,0,0.050000000000000003,0.10000000000000001,0.15000000000000002,0.20000000000000001,0.25,0.30000000000000004,0.35000000000000003,0.40000000000000002,0.45000000000000001,0.5,0.55000000000000004,0.60000000000000009,0.65000000000000002,0.70000000000000007,0.75,0.80000000000000004,0.85000000000000009,0.90000000000000002,0.95000000000000007,0,0.050000000000000003,0.10000000000000001,0.15000000000000002,0.20000000000000001,0.25,0.30000000000000004,0.35000000000000003,0.40000000000000002,0.45000000000000001,0.5,0.55000000000000004,0.60000000000000009,0.65000000000000002,0.70000000000000007,0.75,0.80000000000000004,0.85000000000000009,0.90000000000000002,0,0.050000000000000003,0.10000000000000001,0.15000000000000002,0.20000000000000001,0.25,0.30000000000000004,0.35000000000000003,0.40000000000000002,0.45000000000000001,0.5,0.55000000000000004,0.60000000000000009,0.65000000000000002,0.70000000000000007,0.75,0.80000000000000004,0.85000000000000009,0,0.050000000000000003,0.10000000000000001,0.15000000000000002,0.20000000000000001,0.25,0.30000000000000004,0.35000000000000003,0.40000000000000002,0.45000000000000001,0.5,0.55000000000000004,0.60000000000000009,0.65000000000000002,0.70000000000000007,0.75,0.80000000000000004,0,0.050000000000000003,0.10000000000000001,0.15000000000000002,0.20000000000000001,0.25,0.30000000000000004,0.35000000000000003,0.40000000000000002,0.45000000000000001,0.5,0.55000000000000004,0.60000000000000009,0.65000000000000002,0.70000000000000007,0.75,0,0.050000000000000003,0.10000000000000001,0.15000000000000002,0.20000000000000001,0.25,0.30000000000000004,0.35000000000000003,0.40000000000000002,0.45000000000000001,0.5,0.55000000000000004,0.60000000000000009,0.65000000000000002,0.70000000000000007,0,0.050000000000000003,0.10000000000000001,0.15000000000000002,0.20000000000000001,0.25,0.30000000000000004,0.35000000000000003,0.40000000000000002,0.45000000000000001,0.5,0.55000000000000004,0.60000000000000009,0.65000000000000002,0,0.050000000000000003,0.10000000000000001,0.15000000000000002,0.20000000000000001,0.25,0.30000000000000004,0.35000000000000003,0.40000000000000002,0.45000000000000001,0.5,0.55000000000000004,0.60000000000000009,0,0.050000000000000003,0.10000000000000001,0.15000000000000002,0.20000000000000001,0.25,0.30000000000000004,0.35000000000000003,0.40000000000000002,0.45000000000000001,0.5,0.55000000000000004,0,0.050000000000000003,0.10000000000000001,0.15000000000000002,0.20000000000000001,0.25,0.30000000000000004,0.35000000000000003,0.40000000000000002,0.45000000000000001,0.5,0,0.050000000000000003,0.10000000000000001,0.15000000000000002,0.20000000000000001,0.25,0.30000000000000004,0.35000000000000003,0.40000000000000002,0.45000000000000001,0,0.050000000000000003,0.10000000000000001,0.15000000000000002,0.20000000000000001,0.25,0.30000000000000004,0.35000000000000003,0.40000000000000002,0,0.050000000000000003,0.10000000000000001,0.15000000000000002,0.20000000000000001,0.25,0.30000000000000004,0.35000000000000003,0,0.050000000000000003,0.10000000000000001,0.15000000000000002,0.20000000000000001,0.25,0.30000000000000004,0,0.050000000000000003,0.10000000000000001,0.15000000000000002,0.20000000000000001,0.25,0,0.050000000000000003,0.10000000000000001,0.15000000000000002,0.20000000000000001,0,0.050000000000000003,0.10000000000000001,0.15000000000000002,0,0.050000000000000003,0.10000000000000001,0,0.050000000000000003,0],\"y\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.050000000000000003,0.050000000000000003,0.050000000000000003,0.050000000000000003,0.050000000000000003,0.050000000000000003,0.050000000000000003,0.050000000000000003,0.050000000000000003,0.050000000000000003,0.050000000000000003,0.050000000000000003,0.050000000000000003,0.050000000000000003,0.050000000000000003,0.050000000000000003,0.050000000000000003,0.050000000000000003,0.050000000000000003,0.050000000000000003,0.10000000000000001,0.10000000000000001,0.10000000000000001,0.10000000000000001,0.10000000000000001,0.10000000000000001,0.10000000000000001,0.10000000000000001,0.10000000000000001,0.10000000000000001,0.10000000000000001,0.10000000000000001,0.10000000000000001,0.10000000000000001,0.10000000000000001,0.10000000000000001,0.10000000000000001,0.10000000000000001,0.10000000000000001,0.15000000000000002,0.15000000000000002,0.15000000000000002,0.15000000000000002,0.15000000000000002,0.15000000000000002,0.15000000000000002,0.15000000000000002,0.15000000000000002,0.15000000000000002,0.15000000000000002,0.15000000000000002,0.15000000000000002,0.15000000000000002,0.15000000000000002,0.15000000000000002,0.15000000000000002,0.15000000000000002,0.20000000000000001,0.20000000000000001,0.20000000000000001,0.20000000000000001,0.20000000000000001,0.20000000000000001,0.20000000000000001,0.20000000000000001,0.20000000000000001,0.20000000000000001,0.20000000000000001,0.20000000000000001,0.20000000000000001,0.20000000000000001,0.20000000000000001,0.20000000000000001,0.20000000000000001,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.30000000000000004,0.30000000000000004,0.30000000000000004,0.30000000000000004,0.30000000000000004,0.30000000000000004,0.30000000000000004,0.30000000000000004,0.30000000000000004,0.30000000000000004,0.30000000000000004,0.30000000000000004,0.30000000000000004,0.30000000000000004,0.30000000000000004,0.35000000000000003,0.35000000000000003,0.35000000000000003,0.35000000000000003,0.35000000000000003,0.35000000000000003,0.35000000000000003,0.35000000000000003,0.35000000000000003,0.35000000000000003,0.35000000000000003,0.35000000000000003,0.35000000000000003,0.35000000000000003,0.40000000000000002,0.40000000000000002,0.40000000000000002,0.40000000000000002,0.40000000000000002,0.40000000000000002,0.40000000000000002,0.40000000000000002,0.40000000000000002,0.40000000000000002,0.40000000000000002,0.40000000000000002,0.40000000000000002,0.45000000000000001,0.45000000000000001,0.45000000000000001,0.45000000000000001,0.45000000000000001,0.45000000000000001,0.45000000000000001,0.45000000000000001,0.45000000000000001,0.45000000000000001,0.45000000000000001,0.45000000000000001,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.55000000000000004,0.55000000000000004,0.55000000000000004,0.55000000000000004,0.55000000000000004,0.55000000000000004,0.55000000000000004,0.55000000000000004,0.55000000000000004,0.55000000000000004,0.60000000000000009,0.60000000000000009,0.60000000000000009,0.60000000000000009,0.60000000000000009,0.60000000000000009,0.60000000000000009,0.60000000000000009,0.60000000000000009,0.65000000000000002,0.65000000000000002,0.65000000000000002,0.65000000000000002,0.65000000000000002,0.65000000000000002,0.65000000000000002,0.65000000000000002,0.70000000000000007,0.70000000000000007,0.70000000000000007,0.70000000000000007,0.70000000000000007,0.70000000000000007,0.70000000000000007,0.75,0.75,0.75,0.75,0.75,0.75,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.80000000000000004,0.85000000000000009,0.85000000000000009,0.85000000000000009,0.85000000000000009,0.90000000000000002,0.90000000000000002,0.90000000000000002,0.95000000000000007,0.95000000000000007,1],\"z\":[1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0,1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0,1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,0,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,0,0,0,0,0,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-0,0,0,0,0,0,0,0,-0,0,0,0,0,0,0,-0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-0,0,0,0,0,-0,0],\"mode\":\"markers\",\"marker\":{\"color\":[1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0,1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0,1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,1,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,0,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,0,0,0,0,0,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,0.66700000000000004,-0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-0,0,0,0,0,0,0,0,-0,0,0,0,0,0,0,-0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-0,0,0,0,0,-0,0],\"size\":3,\"colorscale\":\"Viridis\",\"showscale\":true,\"line\":{\"color\":\"rgba(31,119,180,1)\"}},\"type\":\"scatter3d\",\"error_y\":{\"color\":\"rgba(31,119,180,1)\"},\"error_x\":{\"color\":\"rgba(31,119,180,1)\"},\"line\":{\"color\":\"rgba(31,119,180,1)\"},\"frame\":null}],\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.20000000000000001,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n\nBasin of attraction for the equilibrium population share of Grabbers\n:::\n:::\n\n\nHow could a transition from the Hobbesian equilibrium to a Rousseauian equilibrium occur? The Rousseauian equilibrium requires a sufficiently high number of Punishers, so an exogenous intervention that pushes the share of Punishers beyond the critical value $\\beta^H$ would accomplish such a transition. However, as the Rousseauian equilibrium is a continuum, too small an intervention that pushes the population of Punishers just above the critical threshold, where the system will stay without further interventions, may run the risk of falling back into the basin of attraction of the Hobbesian equilibrium.^[ @Bowles2004, pp. 386-390, discusses the issue of equilibrium selection in more detail and considers some mechanisms that would make the Rousseauian equilibrium more robust.]\n\n::: {.callout-note collapse=\"true\" title=\"Python code\"}\n\n\n::: {.cell}\n\n```{.python .cell-code}\n## Run model for different initialisations\nimport numpy as np\nimport pandas as pd\n\n# Define a function called \"bowles\" that simulates the model for different initializations\ndef bowles(alpha_0, beta_0):\n    \n    # Initialise data arrays\n    pi_S = np.full(Q, 0.5)\n    pi_P = np.full(Q, 0.5)\n    pi_G = np.full(Q, 0.5)\n    pi_bar = np.full(Q, 0.5)\n    \n    alpha = np.empty(Q)\n    beta = np.empty(Q)\n    gamma = np.empty(Q)\n    \n    # Initialise population shares\n    alpha[0] = alpha_0\n    beta[0] = beta_0\n    gamma[0] = round(1 - alpha[0] - beta[0], 2)\n    \n    # Simulate model\n    for t in range(1, Q):\n        alpha[t] = alpha[t-1] + alpha[t-1] * (pi_S[t-1] - pi_bar[t-1]) * d\n        beta[t]  = beta[t-1] + beta[t-1] * (pi_P[t-1] - pi_bar[t-1]) * d\n        gamma[t] = 1 - alpha[t] - beta[t]\n        \n        pi_S[t] = 0.5 * v * (alpha[t] + beta[t])\n        pi_P[t] = (0.5 * v * (alpha[t] + beta[t]) + \n                   (1 - alpha[t] - beta[t]) * (beta[t] * v - (1 - beta[t]) * c))\n        pi_G[t] = (alpha[t] * v + \n                   beta[t] * ((1 - beta[t]) * v - beta[t] * c) + \n                   (1 - alpha[t] - beta[t]) * 0.5 * (v - c))\n        pi_bar[t] = (alpha[t] * pi_S[t] + \n                     beta[t] * pi_P[t] + \n                     (1 - alpha[t] - beta[t]) * pi_G[t])\n    \n    # Return final values in a dataframe\n    return pd.DataFrame({\n        'alpha_0': [alpha_0],\n        'beta_0': [beta_0],\n        'gamma_0': [gamma[0]],\n        'alpha_T': [round(alpha[Q-1], 3)],\n        'beta_T': [round(beta[Q-1], 3)],\n        'gamma_T': [round(gamma[Q-1], 3)],\n        'pi_S_T': [round(pi_S[Q-1], 3)],\n        'pi_P_T': [round(pi_P[Q-1], 3)],\n        'pi_G_T': [round(pi_G[Q-1], 3)],\n        'pi_bar': [round(pi_bar[Q-1], 3)]\n    })\n\n# Create grid of initial values for alpha and beta\nalpha_vals = np.arange(0, 1.05, 0.05)\nbeta_vals = np.arange(0, 1.05, 0.05)\n\ngrid = pd.DataFrame([(a, b) for a in alpha_vals for b in beta_vals],\n                     columns=['alpha_0', 'beta_0'])\n\n# Exclude invalid combinations where alpha + beta > 1\ngrid = grid[grid['alpha_0'] + grid['beta_0'] <= 1].reset_index(drop=True)\n\n# Execute the function over the grid and append data from each run as rows to a dataframe named \"results\"\nresults = pd.concat([bowles(row.alpha_0, row.beta_0) for _, row in grid.iterrows()],\n                    ignore_index=True)\n\n### Create 3D plot (here for endogeneous variables only)\n\n# Load plotly package to create 3D plots — done via import\n\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.io as pio\n\n# Create a 3D scatter plot of the final values of the population shares \n# using the data from different initializations\nfig_endog = go.Figure(\n    data=[\n        go.Scatter3d(\n            x=results['alpha_T'],\n            y=results['beta_T'],\n            z=results['gamma_T'],\n            mode='markers',\n            marker=dict(size=3, showscale=False)\n        )\n    ]\n)\n\nfig_endog.update_layout(\n    scene=dict(\n        xaxis_title='alpha_T',\n        yaxis_title='beta_T',\n        zaxis_title='gamma_T'\n    ),\n    title=''\n)\n\n# Show plot (this will open the plot in a browser)\npio.renderers.default = 'browser'\n#fig_endog.show()\n        \n```\n:::\n\n\n:::\n\n## Analytical discussion\nHere we will formally analyse the equilibria and then their stability.^[We focus on the Hobbesian and Rousseauian equilibria and disregard the less interesting equilibria $\\alpha^*=1$ and $\\gamma^*=1$.]\n\nThe Hobbesian equilibrium occurs for $\\beta^*=0$ and positive values of $\\alpha^*$ and $\\gamma^*$, so that $\\alpha^* + \\gamma^* = 1$. In equilibrium we have $\\dot{\\alpha}=0$, which requires $\\pi^S=\\bar{\\pi}$. With $\\beta^*=0$, we have $\\bar{\\pi}=\\alpha \\pi^S + (1-\\alpha) \\pi^G$. From $\\pi^S = \\alpha \\pi^S + (1-\\alpha) \\pi^G$ and the condition that $(1-\\alpha^*) =\\gamma^*>0$, we get $\\pi^S=\\pi^G$. Using @eq-evolutionary_pi-s and @eq-evolutionary_pi-g, the condition $\\pi^S=\\pi^G$ becomes $0.5v\\alpha=\\alpha v + (1-\\alpha)0.5(v-c)$, which implies:\n$$\n(\\alpha^*,\\gamma^*)=\\left(1-\\frac{v}{c}, \\frac{v}{c}\\right).\n$$\n\nWe can check these analytical solutions numerically:\n\n::: {.cell}\n\n```{.r .cell-code}\n### Compare numerical equilibrium solutions to analytical solutions\nalpha[1,Q]  # numerical\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.3333333\n```\n\n\n:::\n\n```{.r .cell-code}\n1-v/c       # analytical\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.3333333\n```\n\n\n:::\n\n```{.r .cell-code}\ngamma[1,Q]  # numerical\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.6666667\n```\n\n\n:::\n\n```{.r .cell-code}\nv/c         # analytical\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.6666667\n```\n\n\n:::\n\n```{.r .cell-code}\n# Confirm that the payoffs of Sharers and Grabbers are equal in equilibrium\npi_S[1,Q]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.3333333\n```\n\n\n:::\n\n```{.r .cell-code}\npi_G[1,Q]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.3333333\n```\n\n\n:::\n\n```{.r .cell-code}\npi_bar[1,Q]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.3333333\n```\n\n\n:::\n:::\n\n\nThe Rousseauian equilibria occur for $\\gamma^*=0$ and $\\alpha$ + $\\beta$ =1 $. For $\\dot{\\alpha}=\\dot{\\beta}=0$, we require $\\pi^S=\\pi^P=\\bar{\\pi}$, and with $\\gamma^*=0$, we have $\\bar{\\pi}=\\alpha \\pi^S + \\beta \\pi^P$. From $\\pi^S = \\alpha \\pi^S + \\beta \\pi^P$ and $\\beta=(1-\\alpha)$, we get $\\pi^S=\\pi^P$. Using @eq-evolutionary_pi-s and @eq-evolutionary_pi-p, confirms that this equilibrium does require $\\gamma^*=(1-\\alpha^* - \\beta^*)=0$, but it does not allow to pin down unique equilibrium values.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### Confirm that alpha+gamma=1 in the Rousseauian equilibria\nalpha[2,Q]+beta[2,Q]  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n\n```{.r .cell-code}\nalpha[3,Q]+beta[3,Q]  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n\n```{.r .cell-code}\n# Confirm that the payoffs of Sharers and Punishers are equal in equilibrium\npi_S[2,Q]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n\n```{.r .cell-code}\npi_P[2,Q]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n\n```{.r .cell-code}\npi_bar[2,Q]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n:::\n\nNext, we analyse the stability properties of the Hobbesian and Roussauian equilibrium, respectively. The Jacobian matrix for the dynamic system in @eq-evolutionary_alpha-dot and @eq-evolutionary_beta-dot is given by:\n$$\nJ(\\alpha, \\beta) = \n\\begin{bmatrix}\n\\pi_t^S - \\bar{\\pi}_t + \\alpha_t \\frac{\\partial (\\pi^S - \\bar{\\pi})}{\\partial \\alpha} & \\alpha_t \\frac{\\partial (\\pi^S - \\bar{\\pi})}{\\partial \\beta} \\\\\n\\beta_t \\frac{\\partial (\\pi^P - \\bar{\\pi})}{\\partial \\alpha} & \\pi_t^P - \\bar{\\pi}_t + \\beta_t \\frac{\\partial (\\pi^P - \\bar{\\pi})}{\\partial \\beta}.\n\\end{bmatrix}\n$$\n\nThe stability conditions for two-dimensional dynamic systems in continuous time are:\n$$\ntr(J) < 0,\n$$\n\nand\n$$\ndet(J) > 0,\n$$\n\nwhere $tr(J)$ is the trace and $det(J)$ the determinant of the Jacobian matrix.\n\nIn the Hobbesian equilibrium, where $\\beta^*=0$ and $\\pi_t^S=  \\bar{\\pi}_t$, the Jacobian becomes:\n\n$$\nJ^*_H = \n\\begin{bmatrix}\n\\alpha^* \\frac{\\partial (\\pi^S - \\bar{\\pi})}{\\partial \\alpha} & \\alpha^* \\frac{\\partial (\\pi^S - \\bar{\\pi})}{\\partial \\beta} \\\\\n0 & \\beta^* \\frac{\\partial (\\pi^P - \\bar{\\pi})}{\\partial \\beta}\n\\end{bmatrix},\n$$\n\ngiving\n\n$$\ntr(J^*_H) = \\alpha^* \\frac{\\partial (\\pi^S - \\bar{\\pi})}{\\partial \\alpha} + \\pi^P - \\bar{\\pi}\n$$\n\nand\n\n$$\n\\det(J^*_H)= \\left[ \\alpha^* \\frac{\\partial (\\pi^S - \\bar{\\pi})}{\\partial \\alpha} \\right] \\left( \\pi^P - \\bar{\\pi} \\right).\n$$\n\nUsing @eq-evolutionary_pi-p and @eq-evolutionary_pi-avr and imposing $\\beta^*=0$, we have \n\n$$\n\\pi^P - \\bar{\\pi} = -0.5(1-\\alpha^*)[c(1+\\alpha)+v] < 0.\n$$\n\nThus, for $\\det(J^*_H) >0$, we need $\\frac{\\partial (\\pi^S - \\bar{\\pi})}{\\partial \\alpha}< 0$.\n\nUsing @eq-evolutionary_pi-s and and @eq-evolutionary_pi-avr, we can derive:\n$$\n\\frac{\\partial (\\pi^S - \\bar{\\pi})}{\\partial \\alpha} = \\frac{\\partial \\pi^P}{\\partial \\alpha} (1 - \\beta_t) \n- \\pi^S_t \n- \\alpha_t \\frac{\\partial \\pi^S}{\\partial \\alpha} \n- \\frac{\\partial \\beta}{\\partial \\alpha} \\pi^P_t \n- (1 - \\alpha_t - \\beta_t) \\frac{\\partial \\pi^G}{\\partial \\alpha} \n+ \\left(1 + \\frac{\\partial \\beta}{\\partial \\alpha}\\right) \\pi^G_t.\n$$\n\nUsing @eq-evolutionary_pi-s and @eq-evolutionary_pi-g, and imposing $\\beta^*=0$, $\\pi^P = \\pi^S = \\bar{\\pi}$, as well as $\\frac{\\partial \\beta}{\\partial \\alpha} = 0$ gives:^[Since we have $\\alpha+\\gamma=1$, $\\alpha$ is independent of $\\beta$, so that $\\frac{\\partial \\beta}{\\partial \\alpha} = 0$.]\n$$\n\\frac{\\partial (\\pi_t^S - \\bar{\\pi})}{\\partial \\alpha} = -0.5v < 0,\n$$\n\nso that $\\det(J^*_H) >0$ and $tr(J^*_H) < 0$, proving that the Hobbesian equilibrium is stable.\n\nNext, consider the Rousseauian equilibrium where $\\gamma^*=0$ and $\\alpha^*+\\beta^*=1$, so that the Jacobian becomes:\n$$\nJ^*_R = \n\\begin{bmatrix}\n(1 - \\beta^*) \\frac{\\partial (\\pi^S - \\bar{\\pi})}{\\partial \\alpha} & (1 - \\beta^*) \\frac{\\partial (\\pi^S - \\bar{\\pi})}{\\partial \\beta} \\\\\n\\beta^* \\frac{\\partial (\\pi^P - \\bar{\\pi})}{\\partial \\alpha} & \\beta^* \\frac{\\partial (\\pi^P - \\bar{\\pi})}{\\partial \\beta}\n\\end{bmatrix}.\n$$\n\nObserve that if $\\frac{\\partial (\\pi^S - \\bar{\\pi})}{\\partial \\alpha}=\\frac{\\partial (\\pi^P - \\bar{\\pi})}{\\partial \\alpha}$ and $\\frac{\\partial (\\pi^S - \\bar{\\pi})}{\\partial \\beta}=\\frac{\\partial (\\pi^P - \\bar{\\pi})}{\\partial \\beta}$, we'd get $det(J^*_R) = 0$, i.e. the dynamic system would have a zero root yielding a continuum of equilibria that are stable but not self-correcting (also called [Lyapunov stable](https://en.wikipedia.org/wiki/Lyapunov_stability)). From the simulations, we know that this is indeed the case. We will confine the formal proof to showing that under the  Rousseauian equilibrium, we do have $\\frac{\\partial (\\pi^S - \\bar{\\pi})}{\\partial \\alpha}=\\frac{\\partial (\\pi^P - \\bar{\\pi})}{\\partial \\alpha}$. \n\nFirst, using @eq-evolutionary_pi-p and and @eq-evolutionary_pi-avr, we can derive:\n$$\n\\frac{\\partial (\\pi^P - \\bar{\\pi})}{\\partial \\alpha} = \\frac{\\partial \\pi^P}{\\partial \\alpha} (1 - \\beta_t) \n- \\pi^S_t \n- \\alpha_t \\frac{\\partial \\pi^S}{\\partial \\alpha} \n- \\frac{\\partial \\beta}{\\partial \\alpha} \\pi^P_t \n- (1 - \\alpha_t - \\beta_t) \\frac{\\partial \\pi^G}{\\partial \\alpha} \n+ \\left(1 + \\frac{\\partial \\beta}{\\partial \\alpha}\\right) \\pi^G_t.\n$$\n\nObserve that $\\frac{\\partial (\\pi^S - \\bar{\\pi})}{\\partial \\alpha}$ and $\\frac{\\partial (\\pi^P - \\bar{\\pi})}{\\partial \\alpha}$  will be equal if $\\frac{\\partial \\pi^S}{\\partial \\alpha} = \\frac{\\partial \\pi^P}{\\partial \\alpha}$. \n\nWe have:\n$$\n\\frac{\\partial \\pi^S}{\\partial \\alpha} = 0.5v \\left(1 + \\frac{\\partial \\beta}{\\partial \\alpha}\\right)\n$$\nand\n$$\n\\frac{\\partial \\pi^P}{\\partial \\alpha} = 0.5v \\left(1 + \\frac{\\partial \\beta}{\\partial \\alpha}\\right) - \\left[\\beta v - \\alpha c\\right] - \\frac{\\partial \\beta}{\\partial \\alpha} \\left[\\beta v - \\alpha c\\right].\n$$\n\nImposing $\\alpha^* + \\beta^* = 1$, which implies $\\frac{\\partial \\beta}{\\partial \\alpha} = -1$, we get:\n$$\n\\frac{\\partial \\pi^S}{\\partial \\alpha} =\\frac{\\partial \\pi^P}{\\partial \\alpha} = 0,\n$$\n\nconfirming that the derivatives are indeed equal, so that $det(J^*_R) = 0$.\n\n::: {.callout-note collapse=\"true\" title=\"Python code\"}\n\n\n::: {.cell}\n\n```{.python .cell-code}\n### Compare numerical equilibrium solutions for alpha and gamma to analytical solutions\n\nalpha[0, Q-1]  # numerical\n1 - v / c      # analytical\n\ngamma[0, Q-1]  # numerical\nv / c          # analytical\n\n# Confirm that the payoffs of Sharers and Grabbers are equal in equilibrium\npi_S[0, Q-1]\npi_G[0, Q-1]\npi_bar[0, Q-1]\n\n### Confirm that alpha + beta = 1 in the Rousseauian equilibria\nalpha[1, Q-1] + beta[1, Q-1]   \nalpha[2, Q-1] + beta[2, Q-1]   \n\n# Confirm that the payoffs of Sharers and Punishers are equal in equilibrium\npi_S[1, Q-1]\npi_P[1, Q-1]\npi_bar[1, Q-1]\n```\n:::\n\n\n:::\n\n## References\n",
    "supporting": [
      "an_evolutionary_game_theoretic_model_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/htmltools-fill-0.5.8.1/fill.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<script src=\"site_libs/plotly-binding-4.10.4/plotly.js\"></script>\n<script src=\"site_libs/typedarray-0.1/typedarray.min.js\"></script>\n<script src=\"site_libs/jquery-3.5.1/jquery.min.js\"></script>\n<link href=\"site_libs/crosstalk-1.2.1/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/crosstalk-1.2.1/js/crosstalk.min.js\"></script>\n<link href=\"site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/plotly-main-2.11.1/plotly-latest.min.js\"></script>\n<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}